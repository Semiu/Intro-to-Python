{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this example, we will create an SVM model to predict whether a banknote is authentic or forgery based on four image characteristics. Note that the data file does not have headers.\n",
    "\n",
    "## Data file: banknote_authentication.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "\n",
    "### Spark SVM documentation: https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-support-vector-machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('svm').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the data has no headers (column names), we will first create a schema and then import the data into a dataframe with the predefined schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknote_schema = StructType([\n",
    "    StructField('variance',DoubleType(),True),\n",
    "    StructField('skewness',DoubleType(),True),\n",
    "    StructField('kurtosis',DoubleType(),True),\n",
    "    StructField('entropy',DoubleType(),True),\n",
    "    StructField('label',IntegerType(),True),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('banknote_authentication.csv',header=False,schema=banknote_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- variance: double (nullable = true)\n",
      " |-- skewness: double (nullable = true)\n",
      " |-- kurtosis: double (nullable = true)\n",
      " |-- entropy: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+-----+\n",
      "|variance|skewness|kurtosis| entropy|label|\n",
      "+--------+--------+--------+--------+-----+\n",
      "|  3.6216|  8.6661| -2.8073|-0.44699|    0|\n",
      "|  4.5459|  8.1674| -2.4586| -1.4621|    0|\n",
      "|   3.866| -2.6383|  1.9242| 0.10645|    0|\n",
      "|  3.4566|  9.5228| -4.0112| -3.5944|    0|\n",
      "| 0.32924| -4.4552|  4.5718| -0.9888|    0|\n",
      "|  4.3684|  9.6718| -3.9606| -3.1625|    0|\n",
      "|  3.5912|  3.0129| 0.72888| 0.56421|    0|\n",
      "|  2.0922|   -6.81|  8.4636|-0.60216|    0|\n",
      "|  3.2032|  5.7588|-0.75345|-0.61251|    0|\n",
      "|  1.5356|  9.1772| -2.2718|-0.73535|    0|\n",
      "|  1.2247|  8.7779| -2.2135|-0.80647|    0|\n",
      "|  3.9899| -2.7066|  2.3946| 0.86291|    0|\n",
      "|  1.8993|  7.6625| 0.15394| -3.1108|    0|\n",
      "| -1.5768|  10.843|  2.5462| -2.9362|    0|\n",
      "|   3.404|  8.7261| -2.9915|-0.57242|    0|\n",
      "|  4.6765| -3.3895|  3.4896|  1.4771|    0|\n",
      "|  2.6719|  3.0646| 0.37158| 0.58619|    0|\n",
      "| 0.80355|  2.8473|  4.3439|  0.6017|    0|\n",
      "|  1.4479| -4.8794|  8.3428| -2.1086|    0|\n",
      "|  5.2423| 11.0272|  -4.353| -4.1013|    0|\n",
      "+--------+--------+--------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['variance', 'skewness', 'kurtosis', 'entropy', 'label']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['variance', 'skewness', 'kurtosis', 'entropy'],\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- variance: double (nullable = true)\n",
      " |-- skewness: double (nullable = true)\n",
      " |-- kurtosis: double (nullable = true)\n",
      " |-- entropy: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[3.6216,8.6661,-2...|    0|\n",
      "|[4.5459,8.1674,-2...|    0|\n",
      "|[3.866,-2.6383,1....|    0|\n",
      "|[3.4566,9.5228,-4...|    0|\n",
      "|[0.32924,-4.4552,...|    0|\n",
      "|[4.3684,9.6718,-3...|    0|\n",
      "|[3.5912,3.0129,0....|    0|\n",
      "|[2.0922,-6.81,8.4...|    0|\n",
      "|[3.2032,5.7588,-0...|    0|\n",
      "|[1.5356,9.1772,-2...|    0|\n",
      "|[1.2247,8.7779,-2...|    0|\n",
      "|[3.9899,-2.7066,2...|    0|\n",
      "|[1.8993,7.6625,0....|    0|\n",
      "|[-1.5768,10.843,2...|    0|\n",
      "|[3.404,8.7261,-2....|    0|\n",
      "|[4.6765,-3.3895,3...|    0|\n",
      "|[2.6719,3.0646,0....|    0|\n",
      "|[0.80355,2.8473,4...|    0|\n",
      "|[1.4479,-4.8794,8...|    0|\n",
      "|[5.2423,11.0272,-...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a linear SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(maxIter=10,regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_model = lsvc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_preds = lsvc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default metric: area under ROC\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC\n",
      "0.9991790974763112\n"
     ]
    }
   ],
   "source": [
    "print('Area under ROC')\n",
    "print(my_binary_eval.evaluate(lsvc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+----------+\n",
      "|            features|label|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|[-7.0421,9.2,0.25...|    1|[-1.6745789277135...|       1.0|\n",
      "|[-6.7526,8.8172,-...|    1|[-1.7121261863860...|       1.0|\n",
      "|[-6.5235,9.6014,-...|    1|[-1.4322687381681...|       1.0|\n",
      "|[-6.4247,9.5311,0...|    1|[-1.3577114091827...|       1.0|\n",
      "|[-6.3679,8.0102,0...|    1|[-1.6135445011842...|       1.0|\n",
      "|[-6.2003,8.6806,0...|    1|[-1.5077136087375...|       1.0|\n",
      "|[-6.0598,9.2952,-...|    1|[-1.3534450644603...|       1.0|\n",
      "|[-5.8818,7.6584,0...|    1|[-1.4656655618146...|       1.0|\n",
      "|[-5.637,8.1261,0....|    1|[-1.3086341649750...|       1.0|\n",
      "|[-5.4901,9.1048,-...|    1|[-1.1669586533815...|       1.0|\n",
      "|[-5.3012,7.3915,0...|    1|[-1.2296693605402...|       1.0|\n",
      "|[-5.2049,7.259,0....|    1|[-1.2083670603777...|       1.0|\n",
      "|[-5.0676,-5.1877,...|    1|[-1.3518739276978...|       1.0|\n",
      "|[-5.0477,-5.8023,...|    1|[-1.3029370181524...|       1.0|\n",
      "|[-5.0301,7.5032,-...|    1|[-1.1349082230192...|       1.0|\n",
      "|[-4.8554,-5.9037,...|    1|[-1.2780415355669...|       1.0|\n",
      "|[-4.8426,-4.9932,...|    1|[-1.2508652365711...|       1.0|\n",
      "|[-4.4861,-13.2889...|    1|[-1.0114839338167...|       1.0|\n",
      "|[-4.4775,-13.0303...|    1|[-1.0165812021890...|       1.0|\n",
      "|[-4.2859,8.5234,3...|    0|[-0.3112928374957...|       1.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsvc_preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy, precision, and recall\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                            metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_acc = acc_eval.evaluate(lsvc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9686746987951808"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
